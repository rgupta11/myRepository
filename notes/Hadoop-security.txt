Kerberos:
https://www.youtube.com/watch?v=XLBAhz735mg

	-Diff b/w Kerberos and other security protocols like LDAP
		-credentials flow through n/w and can be sniffed easily
		-In LDAP, credentials are still flowing thru n/w though encrypted SHA, SSHA etc
		-Kerberos, credential/pswd naver flow thru n/w
		-It is for trusted Hosts on untrusted n/w becz ur passwrd never flow thru n/w.
		-All kerberised host shld belong to a particular realm.
		-Realm is like a domain
		-Pricipal: 3 kinds of:
			-Server
			-Service
			-User
		-Kerberos aims:
			-Kerberos, credential/pswd naver flow thru n/w
			-Pswd are never stored on client machine, it is immediately discarded after used
			-Pswd are never stored on server encrypted/un-encrypted even on the authntcn server
			-Single-sign on: user is asked to enter pswd once per session
		
		-Terms
			-REALM: 
				-Realm is like a domain
				-Is case sensitive and we generally use CAPITAL letter to create REALM
				-Collection of Principals that belong to same domain
				-So its Authentication administrative domain
				-
			-Principal
				-Any entry in Auth DB
				-syntax: name[/instance]@REALM | rporg1@HADOOP.EMETER.COM
			-KDC: 
				-Key distribution centre
				-Auth server + TGS tickt granting server + Key distribution centre
			-Ticket: Client present this ticket to app server to authntct its identity
			-AS
			-TGS
			-AppServer
			
Lecture Kerberos : https://www.youtube.com/watch?v=bcWxLl8x33c		


-Hadoop Cluster
	-securtiy
		
		1.Authentication.  The  client  authenticates  itself  to  the  Authentication  Server  and
		 receives a timestamped Ticket-Granting Ticket (TGT).
		
		2.  Authorization. The client uses the TGT to request a service ticket from the Ticket-
		Granting Server.
		
		3.  Service request. The client uses the service ticket to authenticate itself to the server
		that is providing the service the client is using. In the case of Hadoop, this might
		be the namenode or the resource manager.
		
		Together, the Authentication Server and the Ticket Granting Server form the Key Dis-
		tribution Center (KDC). 
		
			To use Kerberos authentication with Hadoop, you need to install, configure, and run a KDC (Hadoop does
			not come with one). Your organization may already have a KDC you can use (an Active Directory installation,
			for example); if not, you can set up an MIT Kerberos 5 KDC.
		
		
		-The first step is to enable Kerberos authentication  by  setting  the  
		hadoop.security.authentication  property  in  core-site.xml  to  kerberos.   
		(default  setting  is  simple)

		-We also need to enable service-level authorization by setting  hadoop.security.authorization 
		to true in the same file.
		
		-You may configure access control lists (ACLs) in the
		 hadoop-policy.xml configuration file to control which users and groups have permission
		 to connect to each Hadoop service. 
		
		-The format for an ACL is a comma-separated list of usernames, followed by whitespace,
		 followed   by   a   comma-separated   list   of   group   names
		
		-use the  klist command to see the expiry time of your tickets and kdestroy to invalidate your tickets
		
	-Delegation token
		A delegation token is generated by the server (the namenode, in this case) and can be
		thought of as a shared secret between the client and the server. On the first RPC call to
		the namenode, the client has no delegation token, so it uses Kerberos to authenticate.
		As a part of the response, it gets a delegation token from the namenode. In subsequent
		calls it presents the delegation token, which the namenode can verify (since it generated
		it using a secret key), and hence the client is authenticated to the server.
		When the job has finished, the delegation tokens are invalidated.
	
	-Block access token
		-The client uses the block access token to authenticate
		 itself to datanodes. This is possible only because the namenode shares its secret key used
		 to generate the block access token with datanodes
		-dfs.block.access.token.enable to  true
		
	-The more notable features:	
		-Tasks can be run using the operating system account for the user who submitted
		 the job, rather than the user running the node manager.
		-When tasks are run as the user who submitted the job, the distributed cache (see
		 Distributed Cache” on page 274) is secure. Files that are world-readable are put in
		 a shared cache (the insecure default); otherwise, they go in a private cache, readable
		 only by the owner.
		- The shuffle is secure, preventing a malicious user from requesting another user’s
		 map outputs.
		-



	- Security(Kerberos) pg 348 definitive guide
		-IN hadoop  secure authentication mechanism was missing
		-HDFS file permissions provide only a mechanism for authorization,
			which  controls  what  a  particular  user  can  do  to  a  particular  file.
		-Kerberos says that a user is who they say they are; it’s Hadoop’s job to
			determine whether that user has permission to perform a given action
		-Kerberos and Hadoop
				At a high level, there are three steps that a client must take to access a service when
				using Kerberos, each of which involves a message exchange with a server:
				1. Authentication.  The  client  authenticates  itself  to  the  Authentication  Server  and
					receives a timestamped Ticket-Granting Ticket (TGT).
				2. Authorization. The client uses the TGT to request a service ticket from the Ticket
					Granting Server.
				3. Service Request. The client uses the service ticket to authenticate itself to the server
					that is providing the service the client is using. In the case of Hadoop, this might
					be the namenode or the jobtracker. 	
				Together, the Authentication Server and the Ticket Granting Server form the Key 
				Distribution Center (KDC). T

			- TGTs last for 10 hours by default (and can be
				renewed for up to a week). It’s common to automate authentication at operating system
				login time, thereby providing single sign-on to Hadoop

			- In  cases  where  you  don’t  want  to  be  prompted  for  a  password  (for  running  an
				unattended MapReduce job, for example), you can create a Kerberos keytab file using
				the ktutil command. A keytab is a file that stores passwords and may be supplied to
				kinit with the -t option.

			- Security Example
				- Enable hadoop.security.authentication  property  in  core-site.xml  to  kerberos
					- To use Kerberos authentication with Hadoop, you need to install, configure, and run a KDC (Hadoop
					  does not come with one)
				- Enable service-level authorization by setting hadoop.security.authorization to true in the same file.
				- Property is enabled by setting dfs.block.access.token.enable to true.
				- [[ Configure Access Control Lists (ACLs) in the
					hadoop-policy.xml configuration file to control which users and groups have permission
					to connect to each Hadoop service
					By default, all ACLs are set to *, which means that all users have permission to access each
					service, but on a real cluster you should lock the ACLs down to only those users and
					groups that should have access.
				  ]]
				- We only needed to call kinit once, since the Kerberos ticket is valid for 10 hours 
					(use the klist command to see the expiry time of your tickets and kdestroy to 
					invalidate your tickets)\

			-Delegation Tokens
				- HDFS read operation will involve multiple calls to the namenode and calls to one 
					or more datanodes. Instead of using the three-step Kerberos ticket exchange 
					protocol to authenticate each call, which would present a high load on the 
					KDC on a busy cluster
				- Hadoop uses delegation tokens to allow later authenticated access without having to 
				  contact the KDC again	
				- On the first RPC call to the namenode, the client has no delegation token, 
					so it uses Kerberos to authenticate, and as a part of the response it gets a 
					delegation token from the namenode. In subsequent calls, it presents the 
					delegation token, which the namenode can verify (since it generated it using a secret key)
				- block access token: 
					- The client uses a special kind of delegation token, called a block access token, 
						that the namenode passes to the client in response to a metadata request. 
						The client uses the block access token to authenticate itself to datanodes. 
						This is possible only because the namenode shares its secret key used to generate 
						the block access token with datanodes
				- This property is enabled by setting dfs.block.access.token.enable to true.
				- Delegation tokens are used by the jobtracker and tasktrackers to access HDFS 
					during the course of the job. When the job has finished, the delegation tokens 
					are invalidated.

			- Other Security Enhancements
				- Tasks can be run using the operating system account for the user who submitted 
				  the job, rather than the user running the tasktracker.
					- mapred.task.tracker.task-controller  to org.apache.hadoop.mapred.LinuxTaskController.  
				- Shared cache and Private cache	
					- When  tasks  are  run  as  the  user  who  submitted  the  job,  the  distributed  cache
						(Distributed Cache on page 288) is secure: files that are world-readable are put
						in a shared cache (the insecure default), otherwise they go in a private cache, only
						readable by the owner.
				- Users can view and modify only their own jobs, not others. This is enabled by
				  setting mapred.acls.enabled to true.
				-Configure Hadoop to use a keytab  
					- For a datanode, 
						-Set the dfs.datanode.keytab.file property to the keytab filename
						- dfs.datanode.kerberos.principal to the username to use for the datanode
					-

				-kinit
				-kutil
				-klist
				-kdestroy


-----------------------------------------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------------------------------------

Questions:
